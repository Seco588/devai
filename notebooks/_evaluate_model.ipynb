{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess data\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"models/model.h5\")\n",
    "\n",
    "# Evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_matrix = tf.math.confusion_matrix(y_test, predictions)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Calculate precision, recall and F1 score\n",
    "precision = tf.math.precision_at_k(y_test, predictions, 1)\n",
    "recall = tf.math.recall_at_k(y_test, predictions, 1)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
